\section{Threats}
\label{sec:introTreats}
To consider a filesystem secure it is important to imagine potential adversaries who might attack the system. Considering that \gls{FFS} has no real control of the data stored on the different services, all of the data must be considered to be stored in an insecure system. Even if the users could hide the posts made on the \gls{OWS}, for instance, Twitter, by making their profile private, one must consider that Twitter themselves could be an adversary or that Twitter could potentially give out information, such as tweets or direct messages, to entities such as the police. Twitter's privacy policy mentions that they may share, disclose, and preserve personal information and content posted on the service, even after account deletion for up to \num{18} months\,\cite{TwitterPrivacyPolicy}. Therefore, to achieve security, the data stored must always be encrypted. Therefore, one must assume that an adversary has access to all knowledge about \gls{FFS}, including how the data is converted, encrypted, and posted. Additionally, the user should assume an adversary knows which websites and accounts could host data for the filesystem. However, in these thesis, the assumption is that the adversary does \textbf{not} have the decryption key. Although the data is encrypted, other properties such as the user's IP address can be known and this can expose the user's identity. The problem of these other sources of information external to \gls{FFS} is not addressed in \gls{FFS} but remains for future work.

Other than adversaries for \gls{FFS}, one might also imagine that the underlying services might face attacks that can potentially harm the security of the system or even cause the service to go offline, potentially indefinitely. One solution is to use redundancy - by duplicating the data over multiple services, the user can more confidently believe that their data will be accessible since the probability of all the services that they have used going offline at the same time is lower.

The deniability of \gls{FFS} is an important aspect of the filesystem. Potential threat adversaries are agents that the user is trying to hide the data from, such as governing states. For the system to be completely deniable, an adversary should not be able to gain any information about the potential data in the system, this includes even the existence of data. When \gls{FFS} is unmounted there should be no trace of \gls{FFS} ever being present in the device. This thesis will assume that an adversary is competent and can completely analyze the software and hardware on a given. Furthermore, it is assumed that the adversary can gain access to the user's computer where \gls{FFS} has previously been mounted but that the adversary does \textbf{not} have access to the machine \textit{while} \gls{FFS} is mounted. Additionally, it is assumed that the adversary might have snapshots of the user's computer before and after \gls{FFS} was mounted but that no snapshots were taken while \gls{FFS} was mounted. For instance, a country's border agents might take a snapshot of the computer's storage device every time the user passes through the border, but the user might mount \gls{FFS} during the time inside the country. This requires \gls{FFS} to not change any state of the operating system while it is mounted, such as updating information about when it was last mounted. Such state changes could be noticed using snapshots of the operating system state. During the development of \gls{FFS}, no traces of previously mounted \gls{FFS} instances have been found, although this has not been fully researched. Future work includes analyzing potential lingering modifications to the operating system state \gls{FFS} and \gls{FUSE} while mounted.