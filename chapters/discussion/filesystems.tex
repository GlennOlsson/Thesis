\section{Filesystems}
Figure~\ref{fig:app_bench_ffs_read}, \ref{fig:app_bench_ffs_re_read}, and \ref{fig:app_bench_ffs_rnd_read} show that \gls{FFS} performs poorly for Read operations with a small buffer size. Beginning at \SI{4}{\kilo\byte} buffer size, the performance in general goes up with the first few buffer sizes. This indicates that the overhead of the \gls{FFS} read operation is high as the performance gets better when it can read fewer buffers. Overhead of the read operation includes, among other things, the time to fetch the image from Flickr if it is not in the cache, and decrypting the image which is required even if the image is cached. Further, it is expected that Re-Read should perform better than Read when the file size is small enough to fit in the cache. However, this is not an obvious conclusion that can be drawn from the result. Looking at table~\ref{tbl:data_re-read_ffs}, it shows that there is no significant drop in performance for file sizes bigger than the \SI{5}{\mega\byte} cache file size limit. The performance is even better for the file sizes bigger than the cache file size limit than for the file sizes smaller than the cache file size limit for certain buffer sizes, such as \texttt{buffer size = 512kB} where the performance only increases for bigger file sizes. However, as Figure~\ref{fig:res_box_ffs} shows, the average performance of Re-Read is better than the average performance of Read for \gls{FFS}. This supports the theory that the cache will increase the performance of the filesystem.

One interesting comparison is between the benchmark results of \gls{FFS} and \gls{GCSF}. Both filesystems are cloud-based \gls{FUSE} filesystems dependent on an internet connection to their respective storage servers. Knowing that the benchmarking of the two filesystems was started at the same time, and the \gls{FFS} benchmarking took 41 minutes while the \gls{GCSF} benchmarking took 20 minutes, it is already notable that \gls{GCSF} is overall faster than \gls{FFS} for the specified benchmarking test, using the defined file sizes and buffer sizes. The data presented in Section~\ref{sec:res_bench} and Appendix~\ref{app:bench_data} further confirms the conclusion that \gls{FFS} is slower than \gls{GCSF}. For instance, the Read test of \gls{GCSF} performed in general better than the Read test of \gls{FFS}. The median performance of the \gls{GCSF} Read test is significantly better than the median performance of the \gls{FFS} Read test. Looking at Figure~\ref{fig:res_box_ffs} and Figure~\ref{fig:res_box_gcsf} we can see that \gls{FFS} produced much bigger spread of the values than \gls{GCSF} did, especially for the Write, Re-Write, and Random Write tests. One outlier of the Write test of \gls{FFS} performed at \SI[per-mode = symbol]{88671}{\kilo\byte\per\second}, namely for \texttt{file size = 8192kB, buffer size = 2048kB} as can be seen in Table~\ref{tbl:data_read_ffs}. This is better performance than any of the performance data points of \gls{GCSF} for the Write, Re-Write, and Random Write tests.

Comparing \gls{FFFS} benchmarking results against the \gls{APFS} benchmarking results, we can compare the theoretical best performance of \gls{FFS} against a general-purpose highly-used filesystem. In Table~\ref{tbl:data_read_fejk_ffs} and Table~\ref{tbl:data_read_apfs} we can see that the read operation perform almost similarly for \gls{FFFS} and \gls{APFS}, where \gls{APFS} is in general faster than \gls{FFFS}. However, for certain data points, such as \texttt{file size = 4096kB, buffer size = 4kB}, \gls{FFFS} has higher throughput than \gls{APFS} with \SI[per-mode = symbol]{2\,866\,270}{\kilo\byte\per\second} for \gls{FFFS} and \SI[per-mode = symbol]{2\,402\,508}{\kilo\byte\per\second} for \gls{APFS}. The cache of the filesystems can influence the performance of the read operation a lot. In the case of \gls{FFFS}, the filesystem will cache the written data as long as its size is less the limit of \SI{5}{\mega\byte}. However, there is no significant difference between the \gls{FFFS} performance of reading a file that fits in the \gls{FFFS} cache, and one that does not. All files that are read in \gls{FFFS} that are not in the \gls{FFFS} cache are read from disk, which invokes at least one \gls{APFS} read operation. While the \gls{APFS} read operation called might not be called with the same buffer size as the read operation called by IOZone on \gls{FFFS}, the performance of the \gls{FFFS} read operation cannot exceed the \gls{APFS} read operation. However, the similarity of the performance between the filesystem indicates that \gls{FFS} implements fast read operations, and that the read operation performance of \gls{FFS} depends to a high extent on the internet bandwidth and latency to the \gls{OWS}, as well as the \gls{OWS}'s data processing performance.

While the values of the read operation for \gls{FFFS} and \gls{APFS} are comparable to each other, this is not the case for all tests. For instance is the write operation of \gls{FFFS} much slower than the write operation of \gls{APFS} as can be seen in Table~\ref{tbl:data_write_fejk_ffs} and Table~\ref{tbl:data_write_apfs}. The write operation of \gls{FFFS} has about 2-3\% the performance of the write operation of \gls{APFS}. The reason for this can be the fact that \gls{FFFS} has to encrypt the data stored, including creating all the cryptographic variables such as the salt and the \gls{IV}. While \gls{APFS} is also an encrypted filesystem, it is possible that the cryptographic functions are much faster than for \gls{FFFS} as they for instance can be run in kernel space, while \gls{FFFS} is running in user space.

FFFS and \gls{GCSF} are comparable in some tests, which is interesting as \gls{GCSF} is dependent on an internet connection while \gls{FFFS} is not. The median performance of the Read test on \gls{GCSF} is slightly worse than the medium performance of the Read test on \gls{FFFS}. Meanwhile, the median Re-Read performance of \gls{GCSF} is better than the median Re-Read performance of \gls{FFFS}. This indicates that \gls{GCSF} implements a faster cache than \gls{FFFS}. One reason might be that the \gls{FFFS} cache stores the encrypted version of the image, meaning that before the data is read, the image must first be decrypted and decoded. As Google Drive provides the raw data of the file stored, it is possible that \gls{GCSF} stores the raw data in its cache meaning that the data in the read operation can be returned faster. Re-Write and Random Write tests on \gls{FFFS} outperform the same tests on \gls{GCSF}. This is reasonable as the data written to \gls{GCSF} must be uploaded to Google Drive, while the data written to \gls{FFFS} is stored on the local disk. Uploading \SI{16}{\mega\byte} of data with the average (reference point) upload speed of \SI[per-mode = symbol]{92.95}{\mega\bit\per\second} would take about \SI{1.4}{\second}. Meanwhile, we can see in Table~\ref{tbl:data_write_apfs} that \gls{APFS} can write \SI{16}{\mega\byte} of data as fast as \SI[per-mode = symbol]{1539559}{\kilo\byte\per\second} = \SI[per-mode = symbol]{1549.559}{\mega\byte\per\second}, meaning it would take about \SI{10}{\milli\second} to write the data. However, the data written by \gls{FFFS} is larger than \SI{16}{\mega\byte} as the saved data by \gls{FFFS} is inflated by encryption and PNG attributes.

It is easy to see, and it is not unexpected, that \gls{APFS} outperforms \gls{FFS} in performance. As a professional local filesystem, \gls{APFS} will always have better performance than FFS. Further, like \gls{FFFS}, the performance of \gls{FFS} depends on the performance of \gls{APFS} as the file which is uploaded to Flickr first needs to be saved on disk. This dependency could be removed, for instance by providing the temporary file to the FlickCURL library via a \gls{FUSE} filesystem. Further, the median performance of the Re-Read test on \gls{FFS} is about 72\% of the performance of the Re-Read test on \gls{APFS}. With higher bandwidth and with another \gls{OWS}, it is possible that \gls{FFS} could increase its performance. In contrast, the median performance of the Re-Read test on \gls{FFS} is about 76\% of the median performance of the same test on \gls{GCSF}.