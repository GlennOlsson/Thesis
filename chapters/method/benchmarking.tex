\section{Benchmarking}
This sections describes the methodology and execution of the different filesystem benchmarks. Two different filesystems that are relevant to FFS are compared with the result of two different instances of FFS; one instance that uses Flickr as its OWS, and one instance that uses a FOWS by storing the encoded images in the local filesystem on the test machine.

\subsection{Filesystems}
To analyze the performance of FFS, filesystem benchmarking tools are used to compare FFS against other filesystems that are relevant to FFS. The filesystems FFS is compared to are:
\begin{enumerate}
	\item An encrypted APFS partition on a SSD,
	\item An instance of GCSF, and,
	\item An instance of FFFS using an encrypted APFS filesystem on a SSD as its FOWS.
\end{itemize}
% TODO: Continue. Justify each filesystem choice

The encrypted APFS filesystem was used as reference for a local filesystem without required internet connection. It is the local filesystem of the development environment for FFS. It was selected as it will gives the analyze an example of a normally fast filesystem, and how the benchmark data of FFS and other filesystems looks compared to this local filesystem.

GCSF was used to compare FFS against another network-based filesystem. While GCSF is not a steganographic filesystem, it is a filesystem which stores its data on an OWS, namely Google Drive. The reason GCSF was used instead of, for instance, the official Google Drive mountable filesystem volume provided by the Google Drive Desktop application, is that GCSF provides instant upload of the files and directories to Google Drive. The instant upload provided by GCSF enables us to measure the duration of a file operation easily. For instance, a write operation on a file in GCSF will not complete before the new file data has been completely stored on Google Drive. Another reason why GCSF was chosen was because it is a recent filesystem compared to other related filesystems. Some of the other filesystems discussed in Related filesystems, Section~\ref{sec:rel_fs}, were developed many years before FFS and thus do no longer work as expected, for instance due to changes in the API or that the OWS manages its uploaded data differently than previously, as the case with Twitter.

The instance of FFFS using an FOWS of an encrypted APFS was chosen to be compared to FFS so that the duration time of the filesystem operations could be analyzed further. As the filesystem operations of FFFS are similar to the ones of FFS, other than the network request being replaced by local filesystem operations, it is possible to analyze the effect the OWS latency has on the filesystem speed. Further, as the FOWS used by FFFS (encrypted APFS) is also analyzed and benchmarked, the computation time of the FOWS filesystem operations can be deduced from the benchmark results of FFFS. This enables us to analyze the speed of FFS, independent of the OWS used.

\subsection{Tools}
% TODO: Write about iozone
%	Why it cannot be used for GCSF
%	What we do instead - analyze with the help of certain files and creating/traversing directories
IOZone\,\cite{IozoneFilesystemBenchmark} is a filesystem benchmarking tool, analyzing the performance using different tests\,\cite{iozoneIozoneFilesystemBenchmark}:
\begin{itemize}
	\item Read
	\item Write
	\item Re-read
	\item Re-write
	\item Random read
	\item Random write
	\item Read backwards
	\item Read strided
	\item fread
	\item fwrite
\end{itemize}
The tests are run with different buffer sizes for the read or write operation, and for different file sizes to read from or write to. The maximum file size is set by the user as an argument when running the benchmark, and IOZone starts from a file size of \SI{1024}{\kilo\byte}, doubling the file size until the next file size is greater than the file size specified in the argument. For each file size, the IOZone runs all test for different sizes of the buffer used in the read or write operation. Starting at \SI{4}{\kilo\byte}, the buffer size doubles after all tests have been run, and runs all the tests again with the new buffer size. The biggest buffer size for each file size is the same as the file size. For instance, with a maximum file size set at \SI{2048}{\kilo\byte}, IOZone will run all the tests for:
\begin{enumerate}
	\item File size = \SI{1024}{\kilo\byte}, buffer size = \SI{4}{\kilo\byte},
	\item File size = \SI{1024}{\kilo\byte}, buffer size = \SI{8}{\kilo\byte},
	\item File size = \SI{1024}{\kilo\byte}, buffer size = \SI{16}{\kilo\byte},
	\item File size = \SI{1024}{\kilo\byte}, buffer size = \SI{32}{\kilo\byte},
	\item File size = \SI{1024}{\kilo\byte}, buffer size = \SI{64}{\kilo\byte},
	\item File size = \SI{1024}{\kilo\byte}, buffer size = \SI{128}{\kilo\byte},
	\item File size = \SI{1024}{\kilo\byte}, buffer size = \SI{256}{\kilo\byte},
	\item File size = \SI{1024}{\kilo\byte}, buffer size = \SI{512}{\kilo\byte},
	\item File size = \SI{1024}{\kilo\byte}, buffer size = \SI{1024}{\kilo\byte},
	\item File size = \SI{2048}{\kilo\byte}, buffer size = \SI{4}{\kilo\byte},
	\item File size = \SI{2048}{\kilo\byte}, buffer size = \SI{8}{\kilo\byte},
	\item File size = \SI{2048}{\kilo\byte}, buffer size = \SI{16}{\kilo\byte},
	\item File size = \SI{2048}{\kilo\byte}, buffer size = \SI{32}{\kilo\byte},
	\item File size = \SI{2048}{\kilo\byte}, buffer size = \SI{64}{\kilo\byte},
	\item File size = \SI{2048}{\kilo\byte}, buffer size = \SI{128}{\kilo\byte},
	\item File size = \SI{2048}{\kilo\byte}, buffer size = \SI{256}{\kilo\byte},
	\item File size = \SI{2048}{\kilo\byte}, buffer size = \SI{512}{\kilo\byte},
	\item File size = \SI{2048}{\kilo\byte}, buffer size = \SI{1024}{\kilo\byte}, and
	\item File size = \SI{2048}{\kilo\byte}, buffer size = \SI{2048}{\kilo\byte}
\end{enumerate}
% TODO: Briefly describe each test, what it does

The thesis intended to use IOZone for filesystem benchmarking for all the filesystems to have a unified method of benchmarking. However, while running IOZone on GCSF, it was found that IOZOne crashed when  

Want to analyze with GCSF - How useable it is
Repo has a lot of stars - if comparable useability, it is interesting as we store it freely and encrypted

Write and read text file (eg. 1 Mb)
	Make sure to clear cache/local storage between (maybe both)
Write and read image file
	How long it takes to open the image in eg. preview
Create directory tree (depth 3?) and read file in bottom of tree
	Same with image, see if differs a lot in speed compared to in root

Copy file from local filesystem
Move within filesystem 